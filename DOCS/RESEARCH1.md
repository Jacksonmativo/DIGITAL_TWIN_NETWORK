# Research Notes: Mouseworld Paper Analysis for Network Security Digital Twin

## Document Overview
This document contains specific components and features extracted from the Mouseworld paper that can be integrated into the Network Security Digital Twin project.

---

## üéØ High-Priority Additions

### 1. Traffic Profile Launcher & Scenario Generator
**File**: `devices/traffic_launcher.py`

**Purpose**: Define and orchestrate traffic generation profiles

**Key Features**:
- **Traffic models**: Linear, exponential, burst patterns
- **Experiment duration control**: Time-based scenarios
- **Attack mixing ratios**: Normal vs. malicious traffic percentages
- **Connection rate control**: Connections per second per client
- **Profile templates**: Web browsing, video streaming, P2P, IoT patterns

**Paper Reference**: *"This profile defines the traffic model, e.g. lineal or exponential variation of the connections, the global experiment duration in time"*

---

### 2. Metadata Logging & Collection System
**File**: `twins/metadata_collector.py`

**Purpose**: Collect logs from clients/servers for automatic labeling

**Key Features**:
- **Client metadata**: Browser sessions, connection attempts, protocol types
- **Server metadata**: Response codes, session info, resource access
- **Attack metadata**: Exploit kit activity, malware C2 communications
- **Automatic flow matching**: Match metadata to network flows for labeling

**Paper Reference**: *"All clients and servers generate metadata logs, that identifies the flow generated by the type of client/server"*

---

### 3. Advanced Labeling Module
**File**: `analytics/auto_labeler.py`

**Purpose**: Automatically label network flows without human intervention

**Key Features**:
- **IP-based labeling**: Assign labels based on source/dest IP ranges
- **Port-based labeling**: Identify services by port usage
- **Timing-based labeling**: Label flows during attack injection periods
- **Metadata correlation**: Match client/server logs to flows
- **Multi-class labels**: Normal, DDoS, malware, scanning, tunneling, etc.

**Paper Reference**: *"The labelling process can assign attack labels to all the flows from the last address range"*

---

### 4. Traffic Replay & Injection System
**File**: `devices/traffic_replayer.py`

**Purpose**: Replay previously captured PCAP files for testing

**Key Features**:
- **PCAP replay**: Use tcpreplay-like functionality
- **Field modification**: Change IPs, ports, timestamps
- **Rate control**: Speed up/slow down replay
- **Loop/repeat**: Continuous replay for sustained testing
- **Malware traffic injection**: Replay known malware captures

**Paper Reference**: *"Traffic capture injection tools, allowing to modify some fields and replay any previously captured traffic"*

---

### 5. Honeypot Integration
**File**: `devices/honeypot_manager.py`

**Purpose**: Deploy decoy services to attract and analyze attacks

**Key Features**:
- **SSH honeypot**: Capture brute force attempts
- **Web honeypot**: Detect XSS, SQL injection, scanning
- **Service emulation**: Fake vulnerable services
- **Attack capture**: Log all attacker interactions
- **Automatic labeling**: Tag flows interacting with honeypots as malicious

**Paper Reference**: *"honeypots to simulate vulnerable services"* (cowrie for SSH, glastopf for web)

---

### 6. Flow-Based Feature Extraction
**File**: `analytics/flow_feature_extractor.py`

**Purpose**: Extract ML-ready features from network flows

**Key Features**:
- **Basic features**: src/dst IP/port, protocol, duration, packets, bytes
- **Derived features**:
  - `packets_per_second = packets / duration`
  - `bytes_per_packet = bytes / packets`
  - `bytes_per_second = bytes / duration`
- **Aggregated features**: Connection count (`N_CON` - similar flows)
- **TCP flags**: Convert to integer representation
- **Normalization**: Scale features to 0-1 range for ML

**Paper Reference**: Table 1 shows exact features used

---

### 7. Unsupervised ML Anomaly Detection
**File**: `analytics/anomaly_detectors.py`

**Purpose**: Implement proven anomaly detection algorithms

**Key Features**:
- **Isolation Forest (iForest)**: Tree-based isolation
- **Local Outlier Factor (LOF)**: Density-based detection
- **One-Class SVM (OCSVM)**: Boundary-based detection
- **Performance metrics**: AUC (Area Under Curve), precision, recall
- **Ensemble methods**: Combine multiple detectors

**Paper Reference**: Achieved 99.5% AUC with OCSVM on malware detection

---

### 8. Dataset Storage & Management
**File**: `storage/dataset_manager.py`

**Purpose**: Organize and persist labeled datasets

**Key Features**:
- **Format support**: CSV, NetFlow v9, Parquet
- **Versioning**: Track dataset versions over time
- **Metadata**: Store generation parameters, labels, statistics
- **Train/test splits**: Automated splitting for ML
- **Historical storage**: Archive for continuous learning
- **Dataset catalog**: Search and retrieve by date, type, attack class

**Paper Reference**: *"stored datasets could also be useful for future training scenarios"*

---

### 9. Attack Scenario Templates
**File**: `scenarios/attack_scenarios.py`

**Purpose**: Pre-defined attack scenarios for testing

**DDoS Scenarios**:
- SYN flood
- UDP flood
- DNS amplification
- Slowloris

**Malware Scenarios**:
- Exploit kit traffic (RIG, Angler)
- Ransomware (JAFF, WannaCry patterns)
- Botnet C2 communication
- Data exfiltration

**Network Attack Scenarios**:
- Port scanning (nmap-style)
- Password brute forcing
- DNS cache poisoning
- ARP spoofing

**Paper Reference**: Tested RIG exploit kit and JAFF ransomware

---

### 10. Real-Time Monitoring Console
**File**: `dashboard/monitoring_console.py`

**Purpose**: Live visualization during experiments

**Key Features**:
- **Flow statistics**: Real-time flow counts, protocols, bandwidth
- **Attack detection alerts**: Live anomaly notifications
- **Experiment progress**: Current phase, elapsed time, flows generated
- **Resource monitoring**: CPU, memory, network usage
- **ML model confidence**: Live scoring during detection

**Paper Reference**: *"delivering the identified network flow features to a Console, represented by a graphical dashboard"*

---

## üìä Specific Features from Mouseworld Table 1

Implementation of exact features for ML compatibility:

```python
FEATURES = {
    'FIRST_SEEN': 'Flow starting timestamp',
    'IPV4_SRC': 'Source IP address',
    'IPV4_DST': 'Destination IP address',
    'DURATION': 'Flow duration in seconds',
    'L4_SRC_PORT': 'Source port',
    'L4_DST_PORT': 'Destination port',
    'PROTOCOL': 'TCP/UDP/ICMP (as integer)',
    'TCP_FLAGS': 'TCP flags in NetFlow format',
    'PKTS': 'Number of packets per flow',
    'BYTES': 'Number of bytes per flow',
    'PKTS_SEC': 'Packets per second',        # PKTS / DURATION
    'BYTES_SEC': 'Bytes per second',         # BYTES / DURATION
    'BYTES_PKTS': 'Bytes per packet',        # BYTES / PKTS
    'N_CON': 'Similar flow count'            # Count flows with same IPs/port/protocol
}
```

---

## üîß Implementation Priority Order

### Phase 2A - Data Collection Enhancement
1. Flow-based feature extraction
2. Metadata logging system
3. Automatic labeling module
4. Dataset storage manager

### Phase 2B - Traffic Generation
5. Traffic profile launcher
6. Traffic replay system
7. Attack scenario templates
8. Honeypot integration

### Phase 3A - ML Analytics
9. Anomaly detection algorithms (iForest, LOF, OCSVM)
10. Model training pipeline
11. Performance validation (AUC metrics)
12. Real-time monitoring console

---

## üéØ Concrete Next Steps

### Immediate (This Week)
1. **Create `analytics/flow_feature_extractor.py`**
   - Implement Table 1 features
   - NetFlow v9 parser
   - CSV export

2. **Create `analytics/auto_labeler.py`**
   - IP-based labeling
   - Time-window labeling
   - Multi-class support

### Short-term (Next 2 Weeks)
3. **Create `devices/traffic_replayer.py`**
   - PCAP replay with scapy
   - Rate control
   - Field modification

4. **Create `scenarios/attack_scenarios.py`**
   - DDoS templates
   - Malware traffic patterns
   - Scanning scenarios

### Medium-term (Next Month)
5. **Create `analytics/anomaly_detectors.py`**
   - Isolation Forest
   - LOF
   - One-Class SVM
   - AUC calculation

6. **Create `dashboard/monitoring_console.py`**
   - Real-time flow visualization
   - Anomaly alerts
   - Experiment tracking

---

## üì¶ Additional Tools to Integrate

### Traffic Generation
- **Breaking Point** (commercial) - Multi-protocol traffic generator
- **tcpreplay** - PCAP replay
- **phantomJS/Selenium** - Realistic browser traffic
- **VLC** - Video streaming traffic

### Attack Tools
- **ncrack** - Password brute forcing
- **hping3** - DDoS simulation
- **nmap** - Port scanning
- **Metasploit** - Exploit framework

### Honeypots
- **cowrie** - SSH honeypot
- **glastopf** - Web honeypot
- **dionaea** - Malware capture

### Data Collection
- **nfcapd** - NetFlow collector
- **Apache Spot** - ML-ready data processing
- **ELK Stack** - Logging and visualization

---

## üéì Key Takeaways from Mouseworld

1. **Automation is critical** - Minimize human intervention
2. **Labeling is automatic** - Use IP ranges, time windows, metadata
3. **Mixed traffic is essential** - Normal + attack traffic together
4. **Replay is powerful** - Reuse known malware PCAP files
5. **Features matter** - Use proven NetFlow features
6. **Validation needs labels** - Even unsupervised ML needs labeled validation data
7. **Storage is important** - Persist datasets for continuous learning

---

## üìù Recommended Implementation Path

**Starting Components** (Most Foundational):
1. **Flow feature extractor** - Foundation for all analytics
2. **Auto-labeler** - Enables ML training and validation
3. **Attack scenarios** - Provides diverse test data

**Reasoning**: These three components form the core data pipeline that enables all subsequent analytics and machine learning capabilities.

---

## Document Metadata
- **Source**: Mouseworld Paper Analysis
- **Project**: Network Security Digital Twin
- **Last Updated**: February 2026
- **Status**: Active Development Planning